{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9afb14a-0a35-443d-b65f-16777e673886",
   "metadata": {},
   "source": [
    "## Обработка естественного языка (natural language processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7fbea78-abf9-401a-91ac-fdbb9ec186e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6d46e1d-1851-406b-8e52-9a0d88da643c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16dcda-6a19-4472-b3ca-bddc06c0e2aa",
   "metadata": {},
   "source": [
    "Перемешать набор данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9ced7dd-bf95-4c8c-8a7c-0e927709e814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11841</th>\n",
       "      <td>John Cassavetes is on the run from the law. He...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19602</th>\n",
       "      <td>It's not just that the movie is lame. It's mor...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45519</th>\n",
       "      <td>Well, if it weren't for Ethel Waters and a 7-y...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25747</th>\n",
       "      <td>I find Alan Jacobs review very accurate concer...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42642</th>\n",
       "      <td>This movie is simply awesome. It is so hilario...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "11841  John Cassavetes is on the run from the law. He...  positive\n",
       "19602  It's not just that the movie is lame. It's mor...  negative\n",
       "45519  Well, if it weren't for Ethel Waters and a 7-y...  negative\n",
       "25747  I find Alan Jacobs review very accurate concer...  positive\n",
       "42642  This movie is simply awesome. It is so hilario...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2123025f-978a-4183-906e-99071c0eb119",
   "metadata": {},
   "source": [
    "#### Трансформирование слов в векторы признаков (на основе счетчиков слов в соответствующих документах):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6a16899-99c6-44eb-b4a4-83bd6a3c787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer()\n",
    "docs = np.array(['The sun is shining',\n",
    "                 'The weather is sweet',\n",
    "                 'The sun is shining, the weather is sweet, '\n",
    "                 'and one and one is two'])\n",
    "bag =  count.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b512e44-c065-4fc6-ba86-9174e4e591a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 6,\n",
       " 'sun': 4,\n",
       " 'is': 1,\n",
       " 'shining': 3,\n",
       " 'weather': 8,\n",
       " 'sweet': 5,\n",
       " 'and': 0,\n",
       " 'one': 2,\n",
       " 'two': 7}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f851a4-73ab-45a7-b0e7-8dacd8a8577c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['and', 'is', 'one', 'shining', 'sun', 'sweet', 'the', 'two',\n",
       "       'weather'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d71a06a2-1025-4b2a-9da8-69ab95b37a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 1, 0, 1],\n",
       "       [2, 3, 2, 1, 1, 1, 2, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c511b6-49d7-4202-8d89-51896277b21a",
   "metadata": {},
   "source": [
    "Значения в векторах матрицы признаков называются сырыми частотами термов (raw term frequency) tf(t, d) - сколько раз терм t встречается в документе d. Порядок слов или термов в предложении и документе не играет роли. Порядок, в котором частоты термов расположены в векторе признаков, определяются индексами в словаре, обычно по алфавиту.\n",
    "\n",
    "Последовательность элементов является 1-граммой. Соприкасающаяся последовательность элементов в NLP - слов, букв или символов - называется n-граммой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e40926a0-58ce-438b-8474-dcc7b7785de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sun is shining'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77c8a2b4-592e-4a9d-a89e-978b31fbcbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['is shining', 'sun is', 'the sun'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count2 = CountVectorizer(ngram_range=(2, 2))\n",
    "bag2 = count2.fit_transform([docs[0]])\n",
    "count2.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db5425b-d9da-42f0-be8e-ae44e15255d9",
   "metadata": {},
   "source": [
    "#### Оценка важности слов с помощью приема tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4262b4a0-9de9-4189-bab7-9aaa92083f32",
   "metadata": {},
   "source": [
    "Частота терма - обратная частота документа.\n",
    "Данная мера может применяться для снижения веса часто встречающихся слов, которые не содержат полезной информации, в векторах признаков.\n",
    "\n",
    "Мера tf-idf может быть определена, как произведение частоты терма на обратную частоту документа:\n",
    "\n",
    "<img src=\"pic/tfidf.png\" width=\"190\"/>\n",
    "tf(t,d) - частота терма, idf(t,d) - обратная частота документа:\n",
    "<img src=\"pic/idf.png\" width=\"190\"/>\n",
    "\n",
    "1. $n_d$ - общееколичество документов\n",
    "2. частота документа $df(d,t)$ - количество документов d, содержащих терм t.\n",
    "\n",
    "3. 1 в знаменателе служит для того, чтобы присвоить ненулевое значение термам, которые встречаются во всех обучающих образцах.\n",
    "\n",
    "4. log используется для того, чтобы гарантировать, что низким частотам документов не назначится слишком большой вес."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07d8371b-9092-40a7-bbe5-557cd11fb86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.43 0.   0.56 0.56 0.   0.43 0.   0.  ]\n",
      " [0.   0.43 0.   0.   0.   0.56 0.43 0.   0.56]\n",
      " [0.5  0.45 0.5  0.19 0.19 0.19 0.3  0.25 0.19]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer(use_idf=True,\n",
    "                         norm='l2',\n",
    "                         smooth_idf=True)  # idf(t,d) + 1\n",
    "np.set_printoptions(precision=2)\n",
    "print(tfidf.fit_transform(count.fit_transform(docs)).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fef3a64-744b-41c6-a910-66c5dfe025b9",
   "metadata": {},
   "source": [
    "smooth_idf=True - полезна для назначения нулевых весов термам, встречающимся во всех документах.\n",
    "\n",
    "Привычно проводить нормализацию сырых частот термов перед вычислением мер tf-idf:\n",
    "$$v_{norm} = \\frac{v}{||v||_2} = \\frac{v}{\\sqrt{v_1^2+v_2^2+...+v_n^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef3cd3f-dc1e-4a42-9976-66645beef1c6",
   "metadata": {},
   "source": [
    "#### Очистка текстовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4987aa9-0d06-4d9f-93ed-437f4dd96567",
   "metadata": {},
   "source": [
    "Необходимо удалить HTML-разметку, а также знаки препинания (кроме эмотиконов вроде смайликов) и другие небуквенные символы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37b3bc5c-77f0-48a1-8c1b-ed8cc4298d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1, 'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc2bbc11-9838-4d7e-ba65-6ffb55865118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a wonderful little production the filming technique is very unassuming very old time bbc fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece the actors are extremely well chosen michael sheen not only has got all the polari but he has all the voices down pat too you can truly see the seamless editing guided by the references to williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece a masterful production about one of the great master s of comedy and his life the realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears it plays on our knowledge and our senses particularly with the scenes concerning orton and halliwell and the sets particularly of their flat with halliwell s murals decorating every surface are terribly well done \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(<?::|;|=) (?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower() +\n",
    "                   ' '.join(emoticons).replace('-', '')))\n",
    "    return text\n",
    "    \n",
    "print(preprocessor(df.loc[1, 'review']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0c9193-e155-4957-8471-900259741810",
   "metadata": {},
   "source": [
    "Применение функции preprocessor ко всем данным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3625dd1-b4b0-4049-8b89-be90b1c082a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11841</th>\n",
       "      <td>john cassavetes is on the run from the law he ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19602</th>\n",
       "      <td>it s not just that the movie is lame it s more...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45519</th>\n",
       "      <td>well if it weren t for ethel waters and a 7 ye...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25747</th>\n",
       "      <td>i find alan jacobs review very accurate concer...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42642</th>\n",
       "      <td>this movie is simply awesome it is so hilariou...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "11841  john cassavetes is on the run from the law he ...  positive\n",
       "19602  it s not just that the movie is lame it s more...  negative\n",
       "45519  well if it weren t for ethel waters and a 7 ye...  negative\n",
       "25747  i find alan jacobs review very accurate concer...  positive\n",
       "42642  this movie is simply awesome it is so hilariou...  positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'] = df['review'].apply(preprocessor)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6703271f-7173-483e-b748-d0e963fd673b",
   "metadata": {},
   "source": [
    "#### Переработка документов в лексемы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b394fc9e-0fe6-46a1-b98d-a6c242131249",
   "metadata": {},
   "source": [
    "Необходимо определить каким образом разделить совокупность текстов на индивидуальные элементы. Самый элементарный вариант разделение очищенных документов на отдельные слова по пробельным символам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9bf97c1-8ffe-4efe-ac5d-c770bac51072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['runners', 'like', 'running', 'and', 'thus', 'they', 'run']\n"
     ]
    }
   ],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "print(tokenizer('runners like running and thus they run'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4869b27-661f-4b81-87a5-e6863e1790ca",
   "metadata": {},
   "source": [
    "Word stemming - стэмминг слов.\n",
    "\n",
    "Нахождение основы слова, это процесс, который представляет собой трансформирование словав в его корневую форму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1e70fe0-a0d1-48df-ad23-bfe05fe7821f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['runner', 'like', 'run', 'and', 'thu', 'they', 'run']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "\n",
    "print(tokenizer_porter('runners like running and thus they run'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2d185f-1824-458f-91b4-813cbd81452d",
   "metadata": {},
   "source": [
    "Удаление стоп слов (таких, как: is, and, has). Удаление стоп-слов может пригодиться, когда приходится иметь дело с сырыми или нормализованными частотами термов вместо мер tf-idf, в которых веса часто встречающихся слов уже понижены."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738a49d2-f5ee-463e-bf50-71c88579775a",
   "metadata": {},
   "source": [
    "Для удаления стоп-слов будет использоваться набор из 127 стоп-слов английского языка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "368b537f-4961-4f3e-82d7-1c30236fe779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zekat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32949652-39ed-4039-a92c-22ff6306243a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['runner', 'like', 'run', 'run', 'lot']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "[w for w in tokenizer_porter('a runner likes running and runs a lot') if\n",
    " w not in stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a241a5b2-d57b-49ca-a00a-7965e6b1f278",
   "metadata": {},
   "source": [
    "#### Обучение логистической регрессионной модели для классификации документов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843f5c0d-ea11-46a6-830e-bfff82462804",
   "metadata": {},
   "source": [
    "Разбитие данных на обучающий и тестовый наборы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dff63ba5-4c5c-4a0b-9c6b-812fa7c8e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.head(25000).loc[:, 'review'].values\n",
    "y_train = df.head(25000).loc[:, 'sentiment'].values\n",
    "\n",
    "X_test = df.tail(25000).loc[:, 'review'].values\n",
    "y_test = df.tail(25000).loc[:, 'sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fae50a99-8733-4a11-b149-44197f052150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  Counter({'negative': 12561, 'positive': 12439})\n",
      "test:  Counter({'positive': 12561, 'negative': 12439})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print('train: ', Counter(y_train))\n",
    "print('test: ', Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "637d08ec-ca91-4c27-9c88-bec849650740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'vect', 'clf', 'vect__analyzer', 'vect__binary', 'vect__decode_error', 'vect__dtype', 'vect__encoding', 'vect__input', 'vect__lowercase', 'vect__max_df', 'vect__max_features', 'vect__min_df', 'vect__ngram_range', 'vect__norm', 'vect__preprocessor', 'vect__smooth_idf', 'vect__stop_words', 'vect__strip_accents', 'vect__sublinear_tf', 'vect__token_pattern', 'vect__tokenizer', 'vect__use_idf', 'vect__vocabulary', 'clf__C', 'clf__class_weight', 'clf__dual', 'clf__fit_intercept', 'clf__intercept_scaling', 'clf__l1_ratio', 'clf__max_iter', 'clf__multi_class', 'clf__n_jobs', 'clf__penalty', 'clf__random_state', 'clf__solver', 'clf__tol', 'clf__verbose', 'clf__warm_start'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# TfidfVectorizer объединяет CountVectorizer и TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)\n",
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                     ('clf', LogisticRegression(random_state=0,\n",
    "                                                solver='liblinear'))])\n",
    "\n",
    "lr_tfidf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61bafeac-208f-4884-a5d3-5439bfce8d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(lowercase=False)),\n",
       "                                       ('clf',\n",
       "                                        LogisticRegression(random_state=0,\n",
       "                                                           solver='liblinear'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'clf__C': [1.0, 10.0, 100.0],\n",
       "                          'clf__penalty': ['l1', 'l2'],\n",
       "                          'vect__ngram_range': [(1, 1)],\n",
       "                          'vect__stop_words': [['i', 'me', 'my', 'myself', 'we',\n",
       "                                                'our', 'ours', 'ourselves',\n",
       "                                                'you', \"you're\", \"you've...\n",
       "                          'vect__stop_words': [['i', 'me', 'my', 'myself', 'we',\n",
       "                                                'our', 'ours', 'ourselves',\n",
       "                                                'you', \"you're\", \"you've\",\n",
       "                                                \"you'll\", \"you'd\", 'your',\n",
       "                                                'yours', 'yourself',\n",
       "                                                'yourselves', 'he', 'him',\n",
       "                                                'his', 'himself', 'she',\n",
       "                                                \"she's\", 'her', 'hers',\n",
       "                                                'herself', 'it', \"it's\", 'its',\n",
       "                                                'itself', ...],\n",
       "                                               None],\n",
       "                          'vect__tokenizer': [<function tokenizer at 0x0000022C25E5D9D0>],\n",
       "                          'vect__use_idf': [False]}],\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [tokenizer],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\n",
    "              {'vect__ngram_range': [(1, 1)],\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [tokenizer],\n",
    "               'vect__use_idf': [False],\n",
    "               'vect__norm': [None],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]}]\n",
    "\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5, verbose=3,\n",
    "                           n_jobs=-1)\n",
    "gs_lr_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43162741-896b-443a-9aae-543f356d80c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [tokenizer, tokenizer_porter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70daf091-ec48-46ce-887c-661f7a16f630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 10.0, 'clf__penalty': 'l2', 'vect__ngram_range': (1, 1), 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer at 0x0000022C25E5D9D0>}\n"
     ]
    }
   ],
   "source": [
    "print(gs_lr_tfidf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59b54a59-6a06-434e-a2de-7792a86276c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89672\n"
     ]
    }
   ],
   "source": [
    "print(gs_lr_tfidf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35ba9747-2122-4207-937e-3cce8f0d1cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89952\n"
     ]
    }
   ],
   "source": [
    "clf = gs_lr_tfidf.best_estimator_\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85999311-f7b0-4613-aaed-bf2c88e6cd61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
